# LECTRA ï¿½

**Lecture Creation & Training with Realistic Audio** â€” AI-powered desktop application for generating educational content with natural speech, interactive quizzes, and multimedia presentations.

---

## ğŸŒŸ Features

### Core Functionality
- ğŸ™ï¸ **Natural AI Speech**: Microsoft Edge TTS with AI-powered prosody tagging
- ğŸ“Š **Auto-Generated Presentations**: Create PowerPoint slides from documents or topics
- ğŸ¬ **Video Generation**: Synchronized video lectures with narration
- ï¿½ **Document Processing**: Support for PDF, DOCX, PPTX, and plain text
- ğŸŒ **Multilingual**: English and Hindi with multiple voice options

### Interactive Study Mode (NEW!)
- ğŸ“ **AI-Generated Quizzes**: Automatic MCQ generation using Ollama LLM
- â¸ï¸ **Smart Video Pausing**: Quiz checkpoints at configurable intervals
- ğŸ’¡ **Hints & Explanations**: Detailed feedback for every question
- ğŸ“ˆ **Progress Tracking**: Real-time scores, accuracy, and session analytics
- ğŸ¨ **Beautiful Glassmorphism UI**: Wood texture with frosted glass design

### Performance
- âš¡ **RTX 5090 Optimized**: Sub-60-second presentation generation
- ğŸš€ **5-10x faster** LLM calls via parallel execution
- ğŸ–¼ï¸ **3-5x faster** image fetching with async downloads
- ğŸ“¦ **2x faster** PPTX creation with overlapped processing
- â±ï¸ **3-4x overall speedup** (150-250s â†’ 50-70s)

---

## ğŸ—ï¸ Architecture

- **Frontend**: Tauri (Rust) + Vue 3 + Tailwind CSS
- **Backend**: Python FastAPI server
- **AI Models**: 
  - Ollama (llama3.1:latest for prosody, llama3.2:3b for quizzes)
  - Microsoft Edge TTS for speech synthesis
- **Database**: PostgreSQL (optional) for job logging
- **Video**: FFmpeg for video generation

---

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

#### Windows
```powershell
# Run setup script
.\setup-v2.ps1

# Launch application
.\launch.ps1
```

#### Linux/macOS
```bash
# Make script executable and run
chmod +x setup.sh
./setup.sh

# Launch application
./launch.sh
```

### Option 2: Manual Setup

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

---

## ğŸ“‹ Prerequisites

### Required Software
- **Python 3.11+** - Backend server
- **Node.js 18+** - Frontend build
- **Rust** - Tauri framework
- **FFmpeg** - Video processing
- **Ollama** - AI model runtime

### Recommended
- **8GB+ RAM** (16GB for quiz generation)
- **GPU** for faster AI processing
- **SSD** for better performance

---

## ğŸ¯ Usage

### Creating a Lecture

1. **Upload Document** or **Generate from Topic**
   - Upload PDF, DOCX, PPTX, or enter a topic
   - Select language and voice
   - Choose whether to generate video

2. **Processing**
   - Document is analyzed and slides are created
   - AI adds natural prosody to narration
   - Audio is synthesized with Edge TTS
   - (Optional) Video is generated with slides + audio

3. **Output**
   - PowerPoint presentation with notes
   - Audio narration (MP3)
   - Video lecture (MP4)
   - Slide timings and subtitles (VTT)

### Interactive Study Mode

1. **Select Project** with existing video
2. **Configure Settings**
   - Quiz frequency (every 2-5 slides)
   - Difficulty level (easy/medium/hard)
3. **Study Session**
   - Video plays automatically
   - Pauses at checkpoints for quizzes
   - 5 AI-generated MCQs per checkpoint
   - Real-time scoring and feedback
   - Hints available without penalty

---

## ğŸ“ Project Structure

```
LECTRA/
â”œâ”€â”€ sidecar/               # Python backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api.py        # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ config.py     # Configuration
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ quiz_generator.py  # AI quiz generation
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ui/                    # Tauri + Vue frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentNotebook.vue
â”‚   â”‚   â”‚   â””â”€â”€ InteractiveStudyMode.vue
â”‚   â”‚   â””â”€â”€ App.vue
â”‚   â””â”€â”€ src-tauri/        # Rust/Tauri code
â”œâ”€â”€ .env.example          # Environment template
â”œâ”€â”€ setup-v2.ps1          # Windows setup
â”œâ”€â”€ setup.sh              # Linux/Mac setup
â”œâ”€â”€ launch.ps1            # Windows launcher
â””â”€â”€ DEPLOYMENT.md         # Deployment guide
```

---

## ğŸ”§ Configuration

### Environment Variables (.env)

```bash
# Ollama API for AI
OLLAMA_URL=http://127.0.0.1:11434

# Output directory for generated content
OUTPUT_ROOT=~/Lectures

# FFmpeg binary path
FFMPEG_BIN=/usr/bin/ffmpeg

# Default TTS voices
DEFAULT_EN_VOICE=en-US-GuyNeural
DEFAULT_HI_VOICE=hi-IN-SwaraNeural

# Database (optional)
DATABASE_URL=postgres://user:pass@localhost:5432/lectra
```

---

## ğŸ“– Documentation

- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Complete deployment guide
- **[STUDY_MODE_GUIDE.md](STUDY_MODE_GUIDE.md)** - Interactive study mode features
- **[OPTIMIZATION_README.md](OPTIMIZATION_README.md)** - Performance optimizations
- **[QUICKSTART.md](QUICKSTART.md)** - Quick start guide
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture details

---

## ğŸ› Troubleshooting

### Common Issues

**Port 8765 already in use**
```powershell
# Windows
Get-Process -Name python | Stop-Process -Force

# Linux/Mac
lsof -i :8765 | grep LISTEN | awk '{print $2}' | xargs kill -9
```

**Ollama connection failed**
```bash
# Check Ollama is running
ollama list

# Pull required models
ollama pull llama3.1:latest
ollama pull llama3.2:3b
```

**Video player not working**
- Ensure FFmpeg is installed and in PATH
- Check file permissions for Lectures folder
- Verify convertFileSrc is used in Tauri

**Quiz generation fails**
- Ensure Ollama is running with llama3.2:3b
- Check sufficient RAM (3GB+ needed)
- Verify metadata.json exists for project

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“œ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Microsoft Edge TTS** - High-quality speech synthesis
- **Ollama** - Local LLM runtime
- **Tauri** - Lightweight desktop framework
- **FastAPI** - Modern Python web framework
- **Vue 3** - Progressive JavaScript framework

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/lectra/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/lectra/discussions)
- **Documentation**: See docs folder

---

**Made with â¤ï¸ for educators and learners**

# 2. Configure environment
cp .env.example .env
# Edit .env with your settings

# 3. Build Python sidecar
cd sidecar
pip install -r requirements.txt
cd ..
.\scripts\build_sidecar.ps1

# 4. Install UI dependencies
cd ui
npm install
cd ..

# 5. Run in dev mode
cd ui
npm ru

### Production Build

```powershell
cd ui
npm run tauri build
# Installer will be in ui/src-tauri/target/release/bundle/
```

## Project Structure

```
LECTRA/
â”œâ”€â”€ ui/                    # Vue 3 + Tailwind frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # NavBar, HeroLogo, GeneratorPanel, etc.
â”‚   â”‚   â”œâ”€â”€ assets/images/ # Wood textures, logo
â”‚   â”‚   â””â”€â”€ App.vue
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ sidecar/               # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ services/      # ollama_client, tts_engine, timing, etc.
â”‚   â”‚   â”œâ”€â”€ api.py         # FastAPI routes
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_sidecar.ps1  # PyInstaller bundler
â””â”€â”€ bin/
    â””â”€â”€ lecture-sidecar.exe # Generated sidecar binary
```

## Usage

1. **Launch App**: Double-click LECTRA icon
2. **Select Language**: EN or HI
3. **Input Text**: Type or use "big sample"
4. **Configure Voice**: Choose from presets or enter custom EdgeTTS voice
5. **Generate**: Creates `~/Lectures/<project>/` with:
   - `tagged.txt` â€” Text with prosody tags
   - `ssml.xml` â€” Azure SSML markup
   - `audio.mp3` â€” Generated speech
   - `timings.json` â€” Per-sentence timing data
   - `subs.vtt` â€” WebVTT subtitles
   - **NEW**: `presentation.pptx` â€” AI-generated slides with images
   - **NEW**: `presentation_video.mp4` â€” Synced video with audio

## âš¡ Performance Optimizations

### Parallel Processing
- **LLM Calls**: All slides generated in parallel with `asyncio.gather()` (5-10x faster)
- **Image Fetching**: All images downloaded concurrently (3-5x faster)
- **PPTX Creation**: Overlapped with image fetching (2x faster)
- **Connection Pooling**: Shared HTTP sessions reduce overhead

### Real-time Profiling
Every generation shows timing breakdown:
```
[â±] Step 1: Generate Outline: 8.42s
[â±] Step 2: Generate Script (Parallel): 12.35s
[â±] Step 3+4: Images + PPTX (Parallel): 15.67s
[â±] Step 8: Synthesize Audio (EdgeTTS): 18.45s
------------------------------------------------------------
TOTAL: 69.69s
```

### Performance Documentation
- **[OPTIMIZATION_README.md](OPTIMIZATION_README.md)** â€” Quick start guide
- **[PERFORMANCE_OPTIMIZATION.md](PERFORMANCE_OPTIMIZATION.md)** â€” Comprehensive 2000+ line guide
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** â€” One-page reference card

## API Endpoints (Sidecar)

- `GET /healthz` â€” Health check
- `POST /generate` â€” Full pipeline (tagging â†’ SSML â†’ audio â†’ timing)
- `POST /estimate` â€” Timing only (no audio generation)
- `POST /generate_presentation` â€” **NEW**: Complete presentation generation (outline â†’ slides â†’ PPTX â†’ audio â†’ video)

## Timing Formula

```
words = tokenize(sentence_without_tags)
base_wpm = {en: 165, hi: 150, voice_overrides}
rate_pct = last [rate=Â±##%] in sentence or fallback
eff_wpm = clamp(base_wpm * (1 + rate_pct/100), 80, 240)
spoken_sec = (words / eff_wpm) * 60
punct_ms = count(",")*200 + count(".")*450 + count("â€¦")*700
tag_pauses = sum([pause=###ms])
duration_sec = spoken_sec + (punct_ms + tag_pauses)/1000
```

## Tech Stack

- Python, FastAPI, EdgeTTS, FFmpeg
- Ollama, Llama-3.1
- PostgreSQL
- Vue 3, Tailwind CSS, Tauri
- Rust (sidecar management)

## Made with â¤ï¸ by Team Just-Git-Gud

---

**License**: MIT  
**Repo**: [github.com/your-org/lectra](https://github.com/your-org/lectra)
